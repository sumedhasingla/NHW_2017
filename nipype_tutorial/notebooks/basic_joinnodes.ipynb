{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/joinnode.png\"  width=\"240\">\n",
    "\n",
    "# JoinNode\n",
    "\n",
    "JoinNode have the opposite effect of [iterables](basic_iteration.ipynb). Where `iterables` split up the execution workflow into many different branches, a JoinNode merges them back into on node. For a more detailed explanation, check out [JoinNode, synchronize and itersource](http://nipype.readthedocs.io/en/latest/users/joinnode_and_itersource.html) from the main homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "Let's consider the very simple example depicted at the top of this page:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nipype import Node, JoinNode, Workflow\n",
    "\n",
    "# Specify fake input node A\n",
    "a = Node(interface=A(), name=\"a\")\n",
    "\n",
    "# Iterate over fake node B's input 'in_file?\n",
    "b = Node(interface=B(), name=\"b\")\n",
    "b.iterables = ('in_file', [file1, file2])\n",
    "\n",
    "# Pass results on to fake node C\n",
    "c = Node(interface=C(), name=\"c\")\n",
    "\n",
    "# Join forked execution workflow in fake node D\n",
    "d = JoinNode(interface=D(),\n",
    "             joinsource=\"b\",\n",
    "             joinfield=\"in_files\",\n",
    "             name=\"d\")\n",
    "\n",
    "# Put everything into a workflow as usual\n",
    "workflow = Workflow(name=\"workflow\")\n",
    "workflow.connect([(a, b, [('subject', 'subject')]),\n",
    "                  (b, c, [('out_file', 'in_file')])\n",
    "                  (c, d, [('out_file', 'in_files')])\n",
    "                  ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, setting up a ``JoinNode`` is rather simple. The only difference to a normal ``Node`` are the ``joinsource`` and the ``joinfield``. ``joinsource`` specifies from which node the information to join is coming and the ``joinfield`` specifies the input field of the JoinNode where the information to join will be entering the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More realistic example\n",
    "\n",
    "Let's consider another example where we have one node that iterates over 3 different numbers and generates randome numbers. Another node joins those three different numbers (each coming from a separate branch of the workflow) into one list. To make the whole thing a bit more realistic, the second node will use the ``Function`` interface to do something with those numbers, before we spit them out again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import JoinNode, Node, Workflow\n",
    "from nipype.interfaces.utility import Function, IdentityInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id):\n",
    "    \"\"\"Generate a random number based on id\"\"\"\n",
    "    import numpy as np\n",
    "    return id + np.random.rand()\n",
    "\n",
    "def merge_and_scale_data(data2):\n",
    "    \"\"\"Scale the input list by 1000\"\"\"\n",
    "    import numpy as np\n",
    "    return (np.array(data2) * 1000).tolist()\n",
    "\n",
    "\n",
    "node1 = Node(Function(input_names=['id'],\n",
    "                      output_names=['data1'],\n",
    "                      function=get_data_from_id),\n",
    "             name='get_data')\n",
    "node1.iterables = ('id', [1, 2, 3])\n",
    "\n",
    "node2 = JoinNode(Function(input_names=['data2'],\n",
    "                          output_names=['data_scaled'],\n",
    "                          function=merge_and_scale_data),\n",
    "                 name='scale_data',\n",
    "                 joinsource=node1,\n",
    "                 joinfield=['data2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(name='testjoin')\n",
    "wf.connect(node1, 'data1', node2, 'data2')\n",
    "eg = wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.write_graph(graph2use='exec')\n",
    "from IPython.display import Image\n",
    "Image(filename='graph_detailed.dot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the input and output of the joinnode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [node for node in eg.nodes() if 'scale_data' in node.name][0].result\n",
    "res.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending to multiple nodes\n",
    "\n",
    "We extend the workflow by using three nodes. Note that even this workflow, the joinsource corresponds to the node containing iterables and the joinfield corresponds to the input port of the JoinNode that aggregates the iterable branches. As before the graph below shows how the execution process is setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id):\n",
    "    import numpy as np\n",
    "    return id + np.random.rand()\n",
    "\n",
    "def scale_data(data2):\n",
    "    import numpy as np\n",
    "    return data2\n",
    "\n",
    "def replicate(data3, nreps=2):\n",
    "    return data3 * nreps\n",
    "\n",
    "node1 = Node(Function(input_names=['id'],\n",
    "                      output_names=['data1'],\n",
    "                      function=get_data_from_id),\n",
    "             name='get_data')\n",
    "node1.iterables = ('id', [1, 2, 3])\n",
    "\n",
    "node2 = Node(Function(input_names=['data2'],\n",
    "                      output_names=['data_scaled'],\n",
    "                      function=scale_data),\n",
    "             name='scale_data')\n",
    "\n",
    "node3 = JoinNode(Function(input_names=['data3'],\n",
    "                          output_names=['data_repeated'],\n",
    "                          function=replicate),\n",
    "                 name='replicate_data',\n",
    "                 joinsource=node1,\n",
    "                 joinfield=['data3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(name='testjoin')\n",
    "wf.connect(node1, 'data1', node2, 'data2')\n",
    "wf.connect(node2, 'data_scaled', node3, 'data3')\n",
    "eg = wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.write_graph(graph2use='exec')\n",
    "Image(filename='graph_detailed.dot.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
